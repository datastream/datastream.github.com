<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Datastream.github.com by datastream</title>
    <link rel="stylesheet" href="/stylesheets/bootstrap.css">
    <link rel="stylesheet" href="/stylesheets/bootstrap-responsive.css">
    <link rel="stylesheet" href="/stylesheets/datastream.css">
    <link rel="stylesheet" href="/stylesheets/pygment_trac.css">
    <script src="/javascripts/bootstrap.min.js"></script>
    <script src="/javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <header class="umbotron subhead" id="overview">
      <div class="container">
        <h1><a href="/">Dev Notes</a></h1>
        <p class="lead">for islive {explore_world; eat_food; sleep}</p>
      </div>
    </header>
    <div class="container well">
<h1>正文</h1>

<p>在此之前我对日志处理的概念只是停留在syslog程序的层次。最近我自己维护的一个日志转发程序可能需要改造以适应 storm 计算集群的需求，所以特地的在这方面做了一些思考。</p>

<h2>背景</h2>

<p>在讲述我的思考前，我想先简单描述一下我的境遇。</p>

<ol>
<li>线上多台服务器的web日志通过rsyslog tcp的方式发送到某台服务器上。</li>
<li>日志接受服务器上也运行rsyslog，直接读取日志，然后将日志写到本地的某个日志管道中。</li>
<li>本地运行我自己写的程序，主要作用是：接受 storm 集群的tcp连接，读取并且发送管道中的日志。</li>
</ol>

<h2>问题</h2>

<p>这个方式主要的问题在于日志读取不是非常稳定。rsyslog本身有缓存，管道文件也有缓存限制。当然平时感觉没有什么问题，但是当遇到大规模DDOS攻击的时候，如果日志发送不够及时，很容易导致日志丢失。</p>

<h2>想法</h2>

<p>因为这个问题，我开始考虑在我当前的日志发送系统中加入消息队列机制。当然一开始BI统计的哥们推荐我用ZeroMQ，只是后面我开始思考的时候，就发现不知不觉就“歪楼”了。
我现在日常主要使用golang做为自己的主力工具开发语言。我在一开始找golang的zeromq的库的时候，发现没有原生的库，都是绑定。在翻了一遍自己star的github项目后，发现<a href="github.com/bitly/nsq">nsq</a>看上去很好，于是开始尝试使用这个。</p>

<h2>实际做法</h2>

<p>在我自己的测试服务器上，我直接使用官方的测试程序，基本能跑到3w msg/s，cpu看上去也只是用了一个，感觉性能还算靠谱。于是决定搭建一个2台服务器组成的集群玩玩。简单的花了1个小时左右，实现了一个从tcp端口readline，然后将数据推送到nsqd的程序。</p>

<p>基本逻辑如下：</p>

<ol>
<li>程序启动时读取nsqlookupd的地址，然后直接通过nsqlookupd的http接口拿到所有的nsqd节点的ip和端口。</li>
<li>本地监听 tcp端口，接受服务器推送的数据，按行读取，发送到<code>管道A</code>。</li>
<li>程序直接对所有的nsqd节点做tcp连接，等待<code>管道A</code>的数据。</li>
</ol>

<p>这样做看上去很好，可以充分所有的nsqd节点工作。</p>

<h2>隐患</h2>

<ol>
<li>数据每次只是发送到一个nsqd节点，如果该节点直接掉电或者内核挂掉，nsqd缓存在内存的数据会怎么样？</li>
<li>如果转发程序readline后，还没有来得及推送到nsqd节点就挂掉会怎么样？尤其是为了性能，使用了<code>MultiPublish</code>函数。</li>
</ol>

<h2>可能的解决方案</h2>

<ol>
<li>一份数据发往2个nsqd节点。然后一旦挂掉一个，就换节点读取。</li>
<li>直接不过转发程序，专门定制基于nsqd的日志库。</li>
</ol>

<p>方案1： 成本有点大，一般只有高可靠性的日志需要这样搞。当然一般情况下高可靠要求的日志（比如说计费相关日志），数量上不会太多。如果真的很多，那么也只有花钱搞了。</p>

<p>方案2： 需要额外的开发。比如说写类似log4j的插件，客户端运行程序读取本地文件转发等。</p>

<h2>总结</h2>

<p>基本上凡是需要做到高可靠的日志系统，最后都不得不自己开发日志发送插件或者程序。寄希望于syslog稳定性是错误的做法。关键日志其实发多份才可靠。因为单节点情况下，即使每条日志在处理的第一时间写入到硬盘，也会遇到硬盘挂掉的情况，而且这样做需要每条日志做磁盘sync，效率及其低下。</p>
    </div>
    <footer>
      <p>Hosted on GitHub Pages &mdash; Wrote by <a href="https://github.com/datastream">datastream</a></p>
    </footer>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

  </body>
</html>
