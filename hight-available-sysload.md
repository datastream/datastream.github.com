# 正文

>   在此之前我对日志处理的概念只是停留在syslog程序的层次。最近我自己维护的一个日志转发程序可能需要改造以适应 storm 计算集群的需求，所以特地的在这方面做了一些思考。

## 背景

>   在讲述我的思考前，我想先简单描述一下我的境遇。
       1.  线上多台服务器的web日志通过rsyslog tcp的方式发送到某台服务器上。
       2.  日志接受服务器上也运行rsyslog，直接读取日志，然后将日志写到本地的某个日志管道中。
       3.  本地运行我自己写的程序，主要作用是：接受 storm 集群的tcp连接，读取并且发送管道中的日志。

## 问题

>   这个方式主要的问题在于日志读取不是非常稳定。rsyslog本身有缓存，管道文件也有缓存限制。当然平时感觉没有什么问题，但是当遇到大规模DDOS攻击的时候，如果日志发送不够及时，很容易导致日志丢失。

## 想法

>   因为这个问题，我开始考虑在我当前的日志发送系统中加入消息队列机制。当然一开始BI统计的哥们推荐我用ZeroMQ，只是后面我开始思考的时候，就发现不知不觉就“歪楼”了。
>   我现在日常主要使用golang做为自己的主力工具开发语言。我在一开始找golang的zeromq的库的时候，发现没有原生的库，都是绑定。在翻了一遍自己star的github项目后，发现[nsq](github.com/bitly/nsq)看上去很好，于是开始尝试使用这个。

## 实际做法

>   在我自己的测试服务器上，我直接使用官方的测试程序，基本能跑到3w msg/s，cpu看上去也只是用了一个，感觉性能还算靠谱。于是决定搭建一个2台服务器组成的集群玩玩。简单的花了1个小时左右，实现了一个从tcp端口readline，然后将数据推送到nsqd的程序。

基本逻辑如下：

   1. 程序启动时读取nsqlookupd的地址，然后直接通过nsqlookupd的http接口拿到所有的nsqd节点的ip和端口。
   2. 本地监听 tcp端口，接受服务器推送的数据，按行读取，发送到`管道A`。
   3. 程序直接对所有的nsqd节点做tcp连接，等待`管道A`的数据。

这样做看上去很好，可以充分所有的nsqd节点工作。

## 隐患

   1. 数据每次只是发送到一个nsqd节点，如果该节点直接掉电或者内核挂掉，nsqd缓存在内存的数据会怎么样？
   2. 如果转发程序readline后，还没有来得及推送到nsqd节点就挂掉会怎么样？尤其是为了性能，使用了`MultiPublish`函数。

## 可能的解决方案

   1. 一份数据发往2个nsqd节点。然后一旦挂掉一个，就换节点读取。
   2. 直接不过转发程序，专门定制基于nsqd的日志库。

>方案1： 成本有点大，一般只有高可靠性的日志需要这样搞。当然一般情况下高可靠要求的日志（比如说计费相关日志），数量上不会太多。如果真的很多，那么也只有花钱搞了。
>方案2： 需要额外的开发。比如说写类似log4j的插件，客户端运行程序读取本地文件转发等。


## 总结

>   基本上凡是需要做到高可靠的日志系统，最后都不得不自己开发日志发送插件或者程序。寄希望于syslog稳定性是错误的做法。关键日志其实发多份才可靠。因为单节点情况下，即使每条日志在处理的第一时间写入到硬盘，也会遇到硬盘挂掉的情况，而且这样做需要每条日志做磁盘sync，效率及其低下。
